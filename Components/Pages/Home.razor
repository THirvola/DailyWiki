@using System.Text.Json
@page "/"
@rendermode InteractiveServer

<PageTitle>Home</PageTitle>

<h1>Daily Wikipedia page guessing game</h1>
<h2>Category: @category</h2>
<h2>Title: @title</h2>
<h3>hint 1: @hint1</h3>
<p>hint 2:</p> @hint2

@foreach (string option in options)
{
    <button @onclick="(() => {PickAnswer(option);})">@option</button>
}

@code{
    string title = "None";
    string pageId = "0";
    string hint1 = "None";
    string category = "Physics";
    List<string> options = new List<string>();
    MarkupString hint2 = (MarkupString)"None";

    /// <summary>
    /// Ran automatically on initialization. Used for initializing the page
    /// </summary>
    protected override async Task OnInitializedAsync()
    {
        if (title.Equals("None"))
            await FetchPagesInCategory("Physics");

        try
        {
            var client = new HttpClient();
            //GET
            System.Diagnostics.Debug.WriteLine(title);
            HttpResponseMessage resp = await client.GetAsync("https://en.wikipedia.org/w/api.php?action=parse&format=json&page=" + title + "&formatversion=2");
            string respString = await resp.Content.ReadAsStringAsync();

            //Parsing response
            Stream responseStream = resp.Content.ReadAsStream();
            JsonElement jsonRoot = JsonDocument.Parse(responseStream).RootElement;
            JsonElement parseResult = jsonRoot.GetProperty("parse");
            hint1 = CensorHint(title, parseResult.GetProperty("properties").GetProperty("wikibase-shortdesc").GetString()!);
            hint2 = ParseWikipediaMarkup(parseResult.GetProperty("text").GetString()!, true, false);
        }
        catch
        {
            //todo: catch errors

        }
    }

    private async Task FetchPagesInCategory(string category)
    {
        //https://en.wikipedia.org/w/api.php?action=query&format=json&list=categorymembers&cmtitle=Category:Games

        List<string> Articles = new List<string>();
        try
        {
            string continueString = "";
            do
            {
                var client = new HttpClient();
                //GET
                HttpResponseMessage resp = await client.GetAsync("https://en.wikipedia.org/w/api.php?action=query&format=json&cmlimit=100&list=categorymembers&cmtitle=Category:" + category + continueString);
                string respString = await resp.Content.ReadAsStringAsync();

                //Parsing response
                Stream responseStream = resp.Content.ReadAsStream();
                JsonElement jsonRoot = JsonDocument.Parse(responseStream).RootElement;
                JsonElement parseResult = jsonRoot.GetProperty("query").GetProperty("categorymembers");

                //Listing all category members
                for (int i = 0; i < parseResult.GetArrayLength(); ++i)
                {
                    if (parseResult[i].GetProperty("ns").GetInt32() == 0)
                        Articles.Add(parseResult[i].GetProperty("title").GetString()!);
                }

                JsonElement continueProperty = new JsonElement();
                jsonRoot.TryGetProperty("continue", out continueProperty);
                if (continueProperty.ValueKind != JsonValueKind.Undefined)
                {
                    continueString = "&cmcontinue=" + continueProperty.GetProperty("cmcontinue").GetString()!;
                }
                else
                    continueString = "";

            } while (continueString.Length > 0);

            //Picking a random article to be the daily article in this category
            title = Articles[new System.Random(GetRandomSeed()).Next(0, Articles.Count)];
            options = Articles;
        }
        catch
        {
            //todo: catch errors

        }
    }

    private void PickAnswer(string answer)
    {
        if (answer.Equals(title))
            System.Diagnostics.Debug.WriteLine("correct!");
        else
            System.Diagnostics.Debug.WriteLine("wrong!");

    }

    private MarkupString ParseWikipediaMarkup(string source, bool stopAtHeader, bool includeRawText)
    {
        string parsed = "";
        //Extracting the paragraphs
        int index = source.IndexOf("<");
        if (index > 0)
            parsed = source.Substring(0, index);
        else if (index < 0)
            parsed = source;
        while (index >= 0 && index < source.Length && source.Substring(index).Contains("<"))
        {
            string tag = source.Substring(index + 1, source.IndexOf(">", index) - index - 1);
            string tagName = tag.Split(' ')[0];
            if (stopAtHeader && tagName.Length == 2 && tagName.StartsWith("h"))
                break;
            if (tag.Equals("p") || tag.Equals("i") || tag.Equals("b") || tagName.Equals("a"))
            {
                int tagEnd = source.IndexOf("</" + tagName + ">", index)+4;
                int nextTagStart = source.IndexOf("<", tagEnd);
                string paragraphContent = source.Substring(index + 2 + tag.Length, tagEnd - index - 6 - tag.Length);
                if (tag.Equals("b") || tag.Equals("i"))
                {
                    parsed += "<" + tag + ">";
                }

                //paragraphs may contain tags such as <sup> that should be removed
                parsed += ParseWikipediaMarkup(paragraphContent, false,true);
                if (tag.Equals("b") || tag.Equals("i") || tag.Equals("p"))
                {
                    parsed += "</" + tag + ">";
                }

                if (nextTagStart > tagEnd && includeRawText)
                    parsed += source.Substring(tagEnd, nextTagStart - tagEnd);
                else if (nextTagStart < 0 && source.Length > tagEnd && includeRawText)
                    parsed += source.Substring(tagEnd);
                index = nextTagStart;
            }
            else if (tag.EndsWith("/") || tag.StartsWith("/") || tagName.Equals("div") || !source.Contains("</" + tagName + ">"))
            {
                int tagEnd = source.IndexOf(">", index)+1;
                int nextTagStart = source.IndexOf("<", tagEnd);
                if (nextTagStart > tagEnd && includeRawText)
                    parsed += source.Substring(tagEnd, nextTagStart - tagEnd);
                else if (nextTagStart < 0 && source.Length > tagEnd && includeRawText)
                    parsed += source.Substring(tagEnd);
                index = nextTagStart;
            }
            else
            {
                int tagEnd = source.IndexOf("</" + tagName + ">", index) + 3 + tagName.Length;
                if (tagEnd < tagName.Length + 3)
                    break;
                int nextTagStart = source.IndexOf("<", tagEnd);
                if (nextTagStart > tagEnd && includeRawText)
                    parsed += source.Substring(tagEnd, nextTagStart - tagEnd);
                else if (nextTagStart < 0 && source.Length > tagEnd && includeRawText)
                    parsed += source.Substring(tagEnd);
                index = nextTagStart;
            }
        }

        parsed = CensorHint(title, parsed);
        return (MarkupString)parsed;
    }

    private string CensorHint(string title, string hint)
    {
        string[] titleWords = title.Split(' ');

        string censoredHint = hint + "";
        for(int i = 0; i < titleWords.Length; ++i)
        {
            censoredHint = censoredHint.Replace(titleWords[i], new String('#', titleWords[i].Length), StringComparison.InvariantCultureIgnoreCase);
        }
        return censoredHint;
    }

    private int GetRandomSeed()
    {
        return DateTime.UtcNow.Year*366 + DateTime.UtcNow.DayOfYear +1;
    }

}